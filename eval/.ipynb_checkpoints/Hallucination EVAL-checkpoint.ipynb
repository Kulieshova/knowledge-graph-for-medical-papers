{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0c7faa8-5ebb-44d4-ba58-0b9a72669d5e",
   "metadata": {},
   "source": [
    "# Hallucination Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7819a9a3-6845-4d12-8513-0f0da0c67239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install deepeval\n",
    "!pip install PyMuPDF\n",
    "!pip install sentence-transformers\n",
    "!pip install numpy==1.19.5 sentence-transformers \n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from deepeval import evaluate\n",
    "from deepeval.metrics import HallucinationMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "import logging\n",
    "import warnings\n",
    "import deepeval\n",
    "import nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e9ddd8-3e5b-4dea-a842-63f06f8f18ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set your API keys\n",
    "PUBMED_API_KEY = \"\"\n",
    "OPENAI_API_KEY = \"\"  # Replace with your OpenAI API key\n",
    "EMAIL = \"KymariBratton@Gmail.com\"\n",
    "\n",
    "# Set up APIs\n",
    "os.environ[\"PUBMED_API_KEY\"] = PUBMED_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "Entrez.email = EMAIL\n",
    "Entrez.api_key = PUBMED_API_KEY\n",
    "\n",
    "\n",
    "\n",
    "def create_and_evaluate_test_cases(senteces, new_rels_file):\n",
    "    \"\"\"Create and evaluate test cases with proper error handling\"\"\"\n",
    "    try:\n",
    "        # Load data\n",
    "        newrels_df = pd.read_csv(new_rels_file)\n",
    "        \n",
    "        test_cases = []\n",
    "        logger.info(\"Creating test cases...\")\n",
    "        \n",
    "        # Create test cases\n",
    "        for _, gt_row in tqdm(annotations_df.iterrows(), total=len(annotations_df)):\n",
    "            # Find matching relationships\n",
    "            matching_rels = newrels_df[\n",
    "                (newrels_df['subj'].str.lower() == gt_row['subj'].lower()) |\n",
    "                (newrels_df['subjSummary'].str.lower() == gt_row['subj'].lower())\n",
    "            ]\n",
    "            \n",
    "            if matching_rels.empty:\n",
    "                continue\n",
    "                \n",
    "            # Get PubMed context\n",
    "            context = get_pubmed_context(\n",
    "                gt_row['subj'],\n",
    "                gt_row['rel'],\n",
    "                gt_row['obj']\n",
    "            )\n",
    "            \n",
    "            # Create test case for each matching relationship\n",
    "            for _, gen_row in matching_rels.iterrows():\n",
    "                test_case = LLMTestCase(\n",
    "                    input=f\"Evaluate the relationship between {gt_row['subj']} and {gt_row['obj']}\",\n",
    "                    actual_output=f\"{gen_row['subj']} {gen_row['rel']} {gen_row['obj']}\",\n",
    "                    expected_output=f\"{gt_row['subj']} {gt_row['rel']} {gt_row['obj']}\",\n",
    "                    context=context\n",
    "                )\n",
    "                test_cases.append(test_case)\n",
    "        \n",
    "        if not test_cases:\n",
    "            logger.error(\"No test cases were created!\")\n",
    "            return\n",
    "            \n",
    "        logger.info(f\"Created {len(test_cases)} test cases\")\n",
    "        \n",
    "        # Set up hallucination metric\n",
    "        hallucination_metric = HallucinationMetric(\n",
    "            threshold=0.5,\n",
    "            model=\"gpt-4-turbo\"\n",
    "        )\n",
    "        \n",
    "        # Evaluate test cases\n",
    "        logger.info(\"Evaluating test cases...\")\n",
    "        evaluation_results = evaluate(test_cases, [hallucination_metric])\n",
    "        \n",
    "        # Process results\n",
    "        scores = []\n",
    "        for result in evaluation_results:\n",
    "            if hasattr(result, 'metrics') and 'HallucinationMetric' in result.metrics:\n",
    "                score = result.metrics['HallucinationMetric'].score\n",
    "                scores.append(score)\n",
    "        \n",
    "        if not scores:\n",
    "            logger.error(\"No valid scores were generated!\")\n",
    "            return\n",
    "            \n",
    "        # Calculate and print statistics\n",
    "        total_cases = len(scores)\n",
    "        avg_score = sum(scores) / total_cases\n",
    "        low_hallucination = sum(1 for score in scores if score < 0.5)\n",
    "        high_hallucination = sum(1 for score in scores if score >= 0.5)\n",
    "        \n",
    "        print(\"\\n=== Hallucination Evaluation Results ===\")\n",
    "        print(f\"Total Test Cases Evaluated: {total_cases}\")\n",
    "        print(f\"Average Hallucination Score: {avg_score:.3f}\")\n",
    "        print(f\"Low Hallucination Cases (<0.5): {low_hallucination} ({(low_hallucination/total_cases)*100:.1f}%)\")\n",
    "        print(f\"High Hallucination Cases (≥0.5): {high_hallucination} ({(high_hallucination/total_cases)*100:.1f}%)\")\n",
    "        \n",
    "        return scores\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in evaluation process: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        scores = create_and_evaluate_test_cases(\n",
    "            annotations_file='Annotations.csv',\n",
    "            new_rels_file='NewRels_Skip2.csv'\n",
    "        )\n",
    "        \n",
    "        if not scores:\n",
    "            print(\"No valid results were generated. Please check the logs for details.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f73221b-0de6-442d-a467-0d009421fe84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: name 'sentences' is not defined\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def create_and_evaluate_test_cases(sentences, predictions, docs_path):\n",
    "    \"\"\"Create and evaluate test cases with local document context\"\"\"\n",
    "    try:\n",
    "        # Load data\n",
    "        \n",
    "        test_cases = []\n",
    "        logger.info(\"Creating test cases...\")\n",
    "        \n",
    "        for p in predictions.iterrows():\n",
    "    \n",
    "            ref = p[1]['ref']\n",
    "            rel = p[1]['rel']\n",
    "            subj = p[1]['subj']\n",
    "            obj = p[1]['obj']\n",
    "            out=f\"{subj} {rel} {obj}\"\n",
    "            \n",
    "            found, match = find(out, sentences)\n",
    "            if found:\n",
    "                idx = sentences.index(match)\n",
    "            else:\n",
    "                continue\n",
    "            sentence_window = [sentences[i] for i in range(idx-2, idx+2)]\n",
    "            halluncination_score = hallucination_test(out,context=sentence_window, extractions = [subj, obj])\n",
    "            total_halluncination_score += halluncination_score\n",
    "\n",
    "            \n",
    "            # Create test case for each matching relationship\n",
    "            for _, gen_row in matching_rels.iterrows():\n",
    "                test_case = LLMTestCase(\n",
    "                    input=f\"Evaluate the relationship between {gt_row['subj']} and {gt_row['obj']}\",\n",
    "                    actual_output=f\"{gen_row['subj']} {gen_row['rel']} {gen_row['obj']}\",\n",
    "                    expected_output=f\"{gt_row['subj']} {gt_row['rel']} {gt_row['obj']}\",\n",
    "                    context=context\n",
    "                )\n",
    "                test_cases.append(test_case)\n",
    "        \n",
    "        if not test_cases:\n",
    "            logger.warning(\"No test cases were created!\")\n",
    "            return\n",
    "            \n",
    "        logger.info(f\"Created {len(test_cases)} test cases\")\n",
    "        \n",
    "        # Set up hallucination metric\n",
    "        hallucination_metric = HallucinationMetric(\n",
    "            threshold=0.5,\n",
    "            model=\"gpt-4-turbo\"\n",
    "        )\n",
    "        \n",
    "        # Evaluate test cases\n",
    "        logger.info(\"Evaluating test cases...\")\n",
    "        evaluation_result = evaluate(test_cases, [hallucination_metric])\n",
    "        \n",
    "        # Debug evaluation attributes only in DEBUG mode\n",
    "        if logger.isEnabledFor(logging.DEBUG):\n",
    "            logger.debug(f\"Evaluation result type: {type(evaluation_result)}\")\n",
    "            logger.debug(f\"Evaluation result attributes: {dir(evaluation_result)}\")\n",
    "        \n",
    "        # Process results\n",
    "        scores = []\n",
    "        # Check if the result has results attribute\n",
    "        if hasattr(evaluation_result, 'results'):\n",
    "            for single_result in evaluation_result.results:\n",
    "                if hasattr(single_result, 'metrics'):\n",
    "                    metric = single_result.metrics.get('HallucinationMetric')\n",
    "                    if metric and hasattr(metric, 'score'):\n",
    "                        scores.append(metric.score)\n",
    "        \n",
    "        if not scores:\n",
    "            logger.warning(\"No valid scores were generated!\")\n",
    "            return\n",
    "            \n",
    "        # Calculate and print statistics\n",
    "        total_cases = len(scores)\n",
    "        avg_score = sum(scores) / total_cases\n",
    "        low_hallucination = sum(1 for score in scores if score < 0.5)\n",
    "        high_hallucination = sum(1 for score in scores if score >= 0.5)\n",
    "        \n",
    "        print(\"\\n=== Hallucination Evaluation Results ===\")\n",
    "        print(f\"Total Test Cases Evaluated: {total_cases}\")\n",
    "        print(f\"Average Hallucination Score: {avg_score:.3f}\")\n",
    "        print(f\"Low Hallucination Cases (<0.5): {low_hallucination} ({(low_hallucination/total_cases)*100:.1f}%)\")\n",
    "        print(f\"High Hallucination Cases (≥0.5): {high_hallucination} ({(high_hallucination/total_cases)*100:.1f}%)\")\n",
    "        \n",
    "        return scores\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in evaluation process: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        docs_path = \"Docs/\"\n",
    "        \n",
    "        scores = create_and_evaluate_test_cases(\n",
    "            sentences,\n",
    "            new_rels_file='NewRels_Skip2.csv',\n",
    "            docs_path=docs_path\n",
    "        )\n",
    "        \n",
    "        if not scores:\n",
    "            print(\"No valid results were generated. Please check the logs for details.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3873951-ef78-464c-aa01-06a38e8a2c4f",
   "metadata": {},
   "source": [
    "# Deep Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db26750-e229-4333-b32b-d98df40470e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52d78970-fbd7-49f4-b8c6-6f35e78345b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/rishikasrinivas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import fitz,os\n",
    "import numpy as np\n",
    "import deepeval\n",
    "# Load a pre-trained model'\n",
    "OPENAI_API_KEY=\"\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# Initialize Python porter stemmer\n",
    "ps = PorterStemmer()\n",
    "def lemmatize(sent):\n",
    "    return [ps.stem(word) for word in sent.split()]\n",
    "#reading the pdf and hand annotation files\n",
    "def read_pdf(pdf_file):\n",
    "    start=False\n",
    "    sentences=[]\n",
    "    start_idx=0\n",
    "    with fitz.open(pdf_file) as pdf_file:\n",
    "        for page_index, page in enumerate(pdf_file):\n",
    "            text = page.get_text(\"text\").lower()\n",
    "            text=text.split(\". \")\n",
    "            for sub in text:\n",
    "                if 'abstract' in sub or 'intro' in sub:\n",
    "                    start=True\n",
    "                    if 'abstract' in sub:\n",
    "                        sub.index('abstract')\n",
    "                    else:\n",
    "                        sub.index('intro')\n",
    "                        \n",
    "                if start:\n",
    "                    sentences.append(sub)\n",
    "                \n",
    "    return sentences\n",
    "def read_files(root_dir, hand):\n",
    "    \n",
    "    lines=[]\n",
    "    for files in os.listdir(root_dir):\n",
    "        if files[-4:] != '.pdf':\n",
    "            continue\n",
    "        sentences = read_pdf(f\"{root_dir}/{files}\")\n",
    "        lines.extend(sentences)\n",
    "\n",
    "    # read in hand annotations\n",
    "    for p in hand.iterrows():\n",
    "        rel = p[1]['rel']\n",
    "        subj = p[1]['subj']\n",
    "        obj = p[1]['obj']\n",
    "        out=f\"{subj} {rel} {obj}\" \n",
    "        lines.append(out)\n",
    "\n",
    "\n",
    "    return lines\n",
    "\n",
    "    return lines\n",
    "hand = pd.read_csv(\"../Results/ground_truth.csv\")\n",
    "sentences = read_files(\"../Docs\",hand)\n",
    "#computing cosine similarity\n",
    "def vec(sentences):\n",
    "    # Encode sentences\n",
    "    embeddings = model.encode([sentences[0], sentences[1]])\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    similarity = util.cos_sim(embeddings[0], embeddings[1])\n",
    "    return similarity.item() # Value close to 1 indicates high similarity\n",
    "    \n",
    "#finding if the target string (relation triplet) is in the src (pdf + hand annotation)\n",
    "def find(target, src):\n",
    "    found=False\n",
    "    matching_sentences=[]\n",
    "    \n",
    "    for idx,sentence in enumerate(src):\n",
    "        subj, obj = f\" {target.split()[0]} \", f\" {target.split()[1]} \"\n",
    "        if subj in sentence and obj in sentence:\n",
    "            idx = find_substring_index(sentences, subj)\n",
    "            matching_sentence=sentence[idx:]\n",
    "            matching_sentences.append(matching_sentence)\n",
    "            found=True\n",
    "            break \n",
    "            \n",
    "        #pred=\" \".join(lemmatize(target))\n",
    "        #test=\" \".join(lemmatize(sentence))\n",
    "        #cos = vec([pred,test])\n",
    "        \n",
    "        elif subj in sentence:# or cos > 0.68:\n",
    "            found=True\n",
    "            st_idx=idx\n",
    "            idx = find_substring_index(sentences, subj)\n",
    "            matching_sentence=sentence[idx:]\n",
    "            matching_sentences.append(matching_sentence)\n",
    "            \n",
    "    print(len(matching_sentences))\n",
    "    return found, matching_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e5a1cb7-10c6-44e8-b085-0134e7339719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([],\n",
       " ['../Results/Temperature1_WithoutExamples.csv'],\n",
       " ['Temperature0point2.csv',\n",
       "  'ground_truth.csv',\n",
       "  'eval_results',\n",
       "  'Temperature1_WithoutExamples.csv',\n",
       "  'Temperature1_WithoutExamples_cleaned.csv',\n",
       "  'NewRels_Skip2_cummulative.csv',\n",
       "  '.ipynb_checkpoints',\n",
       "  'NewRels_Skip3_cummulative.csv',\n",
       "  'NewRels_Skip2_increments.csv',\n",
       "  'NewRels_Skip4_increments.csv',\n",
       "  'Temperature1_WithExamples.csv',\n",
       "  'NewRels_Skip3_increments.csv'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hall, files, pred_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47319956-c25f-4451-8de5-7a9a9c62cc34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============NewRels_Skip3_increments.csv=================\n",
      "0\n",
      "2\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a319e7caeb824f829ff1383b4aded907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import deepeval\n",
    "from deepeval import evaluate\n",
    "from deepeval.metrics import HallucinationMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "import pandas as pd\n",
    "pred_files = os.listdir(\"../Results\")\n",
    "hand = pd.read_csv(\"../Results/ground_truth.csv\")\n",
    "sentences = read_files(\"../Docs\",hand)\n",
    "def hallucination_test(actual_output, context, extractions):\n",
    "    sub, obj = extractions[0], extractions[1]\n",
    "    metric = HallucinationMetric(threshold=0.5)\n",
    "    scores=[]\n",
    "    for c in context:\n",
    "        test_case = LLMTestCase(\n",
    "            input=f\"What is the relationship between {sub} and {obj}\",\n",
    "            actual_output={actual_output},\n",
    "            context=[c]\n",
    "        )\n",
    "        \n",
    "        metric.measure(test_case)\n",
    "        scores.append(metric.score)\n",
    "    test_case = LLMTestCase(\n",
    "        input=f\"What is the relationship between {sub} and {obj}\",\n",
    "        actual_output={actual_output},\n",
    "        context=context\n",
    "    )\n",
    "    metric.measure(test_case)\n",
    "    scores.append(metric.score)\n",
    "    metric.score = min(scores)\n",
    "    \n",
    "    return metric.score\n",
    "\n",
    "import threading\n",
    "\n",
    "import multiprocessing \n",
    "def find_substring_index(lst, substring):\n",
    "    for i, s in enumerate(lst):\n",
    "        if substring in s:  # Check if the substring exists in the string\n",
    "            return i\n",
    "    return -1 \n",
    "def hallucination(sentences, pred_file):\n",
    "    predictions = pd.read_csv(pred_file)\n",
    "    total_halluncination_score = 0\n",
    "    for i,p in enumerate(predictions.iterrows()):\n",
    "        print(i)\n",
    "    \n",
    "        ref = p[1]['ref']\n",
    "        rel = p[1]['rel']\n",
    "        subj = p[1]['subj']\n",
    "        obj = p[1]['obj']\n",
    "        out=f\"{subj} {rel} {obj}\"\n",
    "        \n",
    "        found, matching_sentences = find(out.lower(), sentences)\n",
    "        print(len(matching_sentences))\n",
    "        if found:\n",
    "            halluncination_scores=[]\n",
    "            for match in matching_sentences:\n",
    "                idx = find_substring_index(sentences, match)\n",
    "                sentence_window = [sentences[i] for i in range(idx-1, idx+1)]\n",
    "                halluncination_score = hallucination_test(out,context=sentence_window, extractions = [subj, obj])\n",
    "                halluncination_scores.append(halluncination_score)\n",
    "                \n",
    "                \n",
    "            total_halluncination_score += min(halluncination_scores)\n",
    "        else:\n",
    "            print(f\"Could not find a match for {out}\")\n",
    "            total_halluncination_score += 1\n",
    "            continue\n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "    print(len(predictions), total_halluncination_score)\n",
    "    print(f\"Average hallucination score for predictions_file: {pred_file} is {total_halluncination_score/len(predictions)}\")\n",
    "    return total_halluncination_score/len(predictions)\n",
    "import logging\n",
    "httpx_logger = logging.getLogger(\"httpx\")\n",
    "httpx_logger.setLevel(logging.WARNING)\n",
    "if __name__ == \"__main__\":\n",
    "    hall=[]\n",
    "    files=[]\n",
    "    for pred_file in ['NewRels_Skip3_increments.csv', 'Temperature1_WithoutExamples.csv']:\n",
    "        print(f\"============={pred_file}=================\")\n",
    "        if any(substring in pred_file for substring in [ 'cumm', '.ipynb', 'ground', 'Clean', 'result']):\n",
    "            continue\n",
    "        pred_file=f\"../Results/{pred_file}\"\n",
    "        files.append(pred_file)\n",
    "        hall.append(hallucination(sentences, pred_file))\n",
    "        \n",
    "      \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5079aab8-3234-44d5-b413-6596d870869c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Average hallucination score for predictions_file: ../Results/Temperature0point2.csv is 0.5137614678899083\n",
    "Average hallucination score for predictions_file: ../Results/Temperature1_WithoutExamples.csv is 0.4267241379310345\n",
    "Average hallucination score for predictions_file: ../Results/NewRels_Skip2_increments.csv is 0.6424418604651163\n",
    "\n",
    "Average hallucination score for predictions_file: ../Results/NewRels_Skip4_increments.csv is 0.6369047619047619\n",
    "Average hallucination score for predictions_file: ../Results/NewRels_Skip3_increments.csv is 0.5863636363636363"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "42aae6ed-f4e7-4d55-97c2-d1714b560016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepeval in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.0)\n",
      "Collecting deepeval\n",
      "  Downloading deepeval-2.0.1-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.55.3)\n",
      "Requirement already satisfied: langchain in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.3.4)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.9-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: httpx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.28.0)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from deepeval) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from deepeval) (4.66.4)\n",
      "Requirement already satisfied: pytest in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from deepeval) (8.3.4)\n",
      "Requirement already satisfied: tabulate in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from deepeval) (0.9.0)\n",
      "Requirement already satisfied: typer in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from deepeval) (0.12.5)\n",
      "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from deepeval) (13.9.4)\n",
      "Requirement already satisfied: protobuf in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from deepeval) (4.25.5)\n",
      "Requirement already satisfied: pydantic in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from deepeval) (2.9.2)\n",
      "Requirement already satisfied: sentry-sdk in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from deepeval) (2.19.0)\n",
      "Requirement already satisfied: pytest-repeat in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from deepeval) (0.9.3)\n",
      "Requirement already satisfied: pytest-xdist in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from deepeval) (3.6.1)\n",
      "Requirement already satisfied: portalocker in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from deepeval) (3.0.0)\n",
      "Requirement already satisfied: langchain-core in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from deepeval) (0.3.13)\n",
      "Requirement already satisfied: langchain_openai in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from deepeval) (0.2.4)\n",
      "Requirement already satisfied: langchain-community in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from deepeval) (0.3.3)\n",
      "Requirement already satisfied: docx2txt~=0.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from deepeval) (0.8)\n",
      "Requirement already satisfied: importlib-metadata>=6.0.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from deepeval) (7.0.0)\n",
      "Requirement already satisfied: tenacity~=8.4.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from deepeval) (8.4.2)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.24.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from deepeval) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.24.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from deepeval) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from deepeval) (1.24.0)\n",
      "Collecting grpcio==1.60.1 (from deepeval)\n",
      "  Downloading grpcio-1.60.1-cp312-cp312-macosx_10_10_universal2.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (0.6.1)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (4.12.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain) (3.10.10)\n",
      "Collecting langchain-core (from deepeval)\n",
      "  Using cached langchain_core-0.3.21-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain) (0.3.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain) (0.1.137)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain) (2.1.3)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx) (1.0.7)\n",
      "Requirement already satisfied: idna in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx) (0.14.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from importlib-metadata>=6.0.2->deepeval) (3.21.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core->deepeval) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core->deepeval) (24.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.10)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from opentelemetry-api<2.0.0,>=1.24.0->deepeval) (1.2.15)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.66.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.24.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.24.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.45b0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from opentelemetry-sdk<2.0.0,>=1.24.0->deepeval) (0.45b0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic->deepeval) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic->deepeval) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->deepeval) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->deepeval) (2.2.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-community->deepeval) (0.6.7)\n",
      "Collecting numpy<3,>=1.26.2 (from langchain)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-community->deepeval) (2.6.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain_openai->deepeval) (0.8.0)\n",
      "Requirement already satisfied: iniconfig in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pytest->deepeval) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pytest->deepeval) (1.5.0)\n",
      "Requirement already satisfied: execnet>=2.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pytest-xdist->deepeval) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->deepeval) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->deepeval) (2.18.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from typer->deepeval) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from typer->deepeval) (1.5.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->deepeval) (3.23.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->deepeval) (0.9.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.24.0->deepeval) (1.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core->deepeval) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->deepeval) (0.1.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->deepeval) (1.0.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain_openai->deepeval) (2024.5.15)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->deepeval) (1.0.0)\n",
      "Downloading deepeval-2.0.1-py3-none-any.whl (474 kB)\n",
      "Downloading grpcio-1.60.1-cp312-cp312-macosx_10_10_universal2.whl (9.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain-0.3.9-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached langchain_core-0.3.21-py3-none-any.whl (409 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
      "Installing collected packages: numpy, grpcio, langchain-core, langchain, deepeval\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.3\n",
      "    Uninstalling numpy-2.1.3:\n",
      "      Successfully uninstalled numpy-2.1.3\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.63.2\n",
      "    Uninstalling grpcio-1.63.2:\n",
      "      Successfully uninstalled grpcio-1.63.2\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.13\n",
      "    Uninstalling langchain-core-0.3.13:\n",
      "      Successfully uninstalled langchain-core-0.3.13\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.3.4\n",
      "    Uninstalling langchain-0.3.4:\n",
      "      Successfully uninstalled langchain-0.3.4\n",
      "  Attempting uninstall: deepeval\n",
      "    Found existing installation: deepeval 2.0\n",
      "    Uninstalling deepeval-2.0:\n",
      "      Successfully uninstalled deepeval-2.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "blis 1.0.1 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
      "thinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed deepeval-2.0.1 grpcio-1.60.1 langchain-0.3.9 langchain-core-0.3.21 numpy-1.26.4\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade deepeval openai langchain httpx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32a8f95b-8bcd-413c-ba99-ca45792b556d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36772486772486773"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "69.5/189"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc41c1b-4ab6-44b9-a0d0-6e375a17cf36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
